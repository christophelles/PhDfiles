from pandas import *
import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from mpl_toolkits.mplot3d import Axes3D
from scipy.signal import savgol_filter
from sklearn import svm
from sklearn.cluster import KMeans
from sklearn.cluster import OPTICS
from sklearn.cluster import DBSCAN
from sklearn.cluster import MeanShift
from sklearn.cluster import estimate_bandwidth

#organisation of datafile
dataF = read_csv('file_name.csv')
newdata = dataF.rename(columns={'Wavenumbers [1/cm]':'target'})

#randomise data matrix, run PCA and find average eigenvalues
i = 0
av_lambda = []

while i < 1001:
    newerdata = newdata.sample(frac=1, axis=1).sample(frac=1).reset_index(drop=True)
    xi = newerdata.values
    pca_ = PCA(n_components=428)  #428 is the no. of rows
    pca_loop = pca_.fit_transform(xi)
    pca_loop_eigen = pca_.explained_variance_
    av_eigen = sum(pca_loop_eigen)/428
    av_lambda.append(av_eigen)
    i += 1
    av_lambda
    
average_lambda = sum(av_lambda)/428
print(average_lambda)

# Fit the spectral data and extract the explained variance ratio
skpca1 = sk_pca(n_components=30)
X1 = skpca1.fit(newdata)
print(skpca1.explained_variance_)

#Compare the skpca1.explained_variance to the average_lambda value, 
#PC_number = maximum number of components selected where skpca1.explained_variance > average_lambda

#Find explained variance as a percentage
expl_var_1 = X1.explained_variance_ratio_*100

x_range = []

for i in range(1,31):
    x_range.append(i)

# Plot data
fig, (ax1) = plt.subplots(figsize=(10,8))
fig.set_tight_layout(True)
ax1.plot(x_range, expl_var_1,'-o', label="Explained Variance %")
ax1.plot(x_range, np.cumsum(expl_var_1),'-o', label = 'Cumulative variance %')
ax1.set_xlabel("PC number", fontsize=20)
ax1.set_ylabel("Variance %", fontsize=20)
ax1.set_title('Absorbance data', fontsize=20)
ax1.tick_params(labelsize=18)
    
plt.legend(fontsize='x-large')
plt.show()

#creating table for score plots
x = newdata.values
pca = PCA(n_components= PC_number)
principalComponents = pca.fit_transform(x)
principalDf = pd.DataFrame(data = principalComponents, columns = ['PC_1','PC_2'...,'PC_number'])
finalDf = pd.concat([principalDf, data[['target']]], axis = 1)
pd.set_option("display.max_rows", 176)

#Generic code for plotting score plots
fig = plt.figure(figsize = (8,8))
ax = fig.add_subplot(1, 1, 1)
ax.set_xlabel('Principal Component 1', fontsize = 15)
ax.set_ylabel('Principal Component 2', fontsize = 15)
ax.set_title('Principal Component Analysis', fontsize = 20)

targets = []
colors = []
for target, color in zip(targets,colors):
    indicesToKeep = finalDf['target'] == target
    ax.scatter(finalDf.loc[indicesToKeep, 'PC_1'], finalDf.loc[indicesToKeep, 'PC_2'], c = color, s = 50)
ax.legend(targets)
ax.grid()

#create loadings table
loadings = pca.components_
loadings

loadingDf = DataFrame(loadings)
loadingsDf = loadingDf.T
loadingsDf.columns = ['PC_1','PC_2',...,'PC_number']

wv = read_csv('wv 3600.csv')#this file contained the wavenumbers

pd.set_option("display.max_rows", 1000)

table = pd.concat([wv, loadingsDf], axis = 1)

#Generic plotting of loading plots
%matplotlib notebook

x = table['Wavenumbers [1/cm]']
y = table['PC1']

plt1 = plt.figure(figsize=(10, 7))
plt.plot(x, y)
plt.title('PC1 Loadings', fontsize=20)
plt.xlabel('Wavenumbers $cm^{-1}$', fontsize=20)
plt.ylabel('Loadings for PC1', fontsize=20)
plt.xticks(fontsize=18)
plt.yticks(fontsize=18)
plt.show
