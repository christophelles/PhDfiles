from pandas import *
import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from mpl_toolkits.mplot3d import Axes3D
from scipy.signal import savgol_filter
from sklearn import svm
from sklearn.cluster import KMeans
from sklearn.cluster import OPTICS
from sklearn.cluster import DBSCAN
from sklearn.cluster import MeanShift
from sklearn.cluster import estimate_bandwidth

#organisation of datafile
dataF = read_csv('file_name.csv')
data = dataF.rename(columns={'Wavenumbers [1/cm]':'target'})
newdata = data.drop(columns='target')

#randomise data matrix, run PCA and find average eigenvalues
i = 0
av_lambda = []

while i < 1001:
    newerdata = newdata.sample(frac=1, axis=1).sample(frac=1).reset_index(drop=True)
    xi = newerdata.values
    pca_ = PCA(n_components=len(newdata))
    pca_loop = pca_.fit_transform(xi)
    pca_loop_eigen = pca_.explained_variance_
    av_eigen = sum(pca_loop_eigen)/len(newdata)
    av_lambda.append(av_eigen)
    i += 1
    av_lambda
    
average_lambda = sum(av_lambda)/len(newdata)
print(average_lambda)

# Fit the spectral data and extract the explained variance ratio
skpca1 = sk_pca(n_components=30)
X1 = skpca1.fit(newdata)
lamdas = skpca1.explained_variance_
lamda_lim = [item for item in lamdas if item >= average_lambda]
PC_number = len(lamda_lim)

#Find explained variance as a percentage
expl_var_1 = X1.explained_variance_ratio_*100

x_range = []

for i in range(1,31):
    x_range.append(i)

# Plot data
fig, (ax1) = plt.subplots(figsize=(10,8))
fig.set_tight_layout(True)
ax1.plot(x_range, expl_var_1,'-o', label="Explained Variance %")
ax1.plot(x_range, np.cumsum(expl_var_1),'-o', label = 'Cumulative variance %')
ax1.set_xlabel("PC number", fontsize=20)
ax1.set_ylabel("Variance %", fontsize=20)
ax1.set_title('Absorbance data', fontsize=20)
ax1.tick_params(labelsize=18)
    
plt.legend(fontsize='x-large')
plt.show()

import pandas as pd 
x = newdata.values
pca = PCA(n_components= PC_number)
principalComponents = pca.fit_transform(x)
principalDf = pd.DataFrame(data = principalComponents)
finalDf = pd.concat([principalDf, data[['target']]], axis = 1)

cols = []             
for i in range(1, PC_number+1):
    col = "PC"+str(i)      
    cols.append(col)
else:
    cols.append('target')

finalDf.columns = cols

#Generic code for plotting score plots
fig = plt.figure(figsize = (8,8))
ax = fig.add_subplot(1, 1, 1)
ax.set_xlabel('Principal Component 1', fontsize = 15)
ax.set_ylabel('Principal Component 2', fontsize = 15)
ax.set_title('Principal Component Analysis', fontsize = 20)

targets = []
colors = []
for target, color in zip(targets,colors):
    indicesToKeep = finalDf['target'] == target
    ax.scatter(finalDf.loc[indicesToKeep, 'PC_1'], finalDf.loc[indicesToKeep, 'PC_2'], c = color, s = 50)
ax.legend(targets)
ax.grid()

#create loadings table
loadings = pca.components_
loadingDf = DataFrame(loadings)
loadingsDf = loadingDf.T
loadingsDf.columns = cols

wv = pd.Series(newdata.columns)

pd.set_option("display.max_rows", 1000)

table = pd.concat([wv, loadingsDf], axis = 1)

#Generic plotting of loading plots
%matplotlib notebook

x = table['Wavenumbers [1/cm]']
y = table['PC1']

plt1 = plt.figure(figsize=(10, 7))
plt.plot(x, y)
plt.title('PC1 Loadings', fontsize=20)
plt.xlabel('Wavenumbers $cm^{-1}$', fontsize=20)
plt.ylabel('Loadings for PC1', fontsize=20)
plt.xticks(fontsize=18)
plt.yticks(fontsize=18)
plt.show
